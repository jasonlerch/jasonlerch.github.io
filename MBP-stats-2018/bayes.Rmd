---
title: "Bayesian statistics"
subtitle: "Day 3"
author: "Jason Lerch (with lots of slides from Chris Hammill)"
date: "2018/09/12"
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

<style>
.small {
  font-size: 65%;
}

.medium {
  font-size: 80%;
}

.footnote {
  font-size: 75%;
  color: gray;
}

.smallcode { 

}
.smallcode .remark-code {
  font-size: 50%
}

.smallercode { 

}
.smallercode .remark-code {
  font-size: 75%
}

</style>

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```


# Frequentist Null Hypothesis Testing

- To form conclusions in frequentism we typically lean on null hypothesis testing.
- Null hypotheses are parameter values for your model you'd like to disprove
- If your statistics (and more extreme statistics) would be very unlikely given your null model
  you reject the null hypothesis, and conclude that the null hypothesis is not correct.
- Choosing a threshold for this probability (e.g. 0.05) and rejecting when your p-value
  is below the threshold gives you a fixed probability of making a "Type I" error, 
  which conveniently is equal to your threshold.
- So if we reject all p-values when they are below 0.05 we have a 5% chance of
  rejecting when the null model is in fact true.
- If this is confusing, you're not alone, this is very hard to wrap your mind around.

---

# Fake data simulations

* Intepreting statistical models can be challenging
    
    * this is especially true in the presence of interactions
    
* It is much easier to understand what your statistical tests and models are doing if you know the ground truth.

* The easiest way to know the ground truth is to create it

* Let's do that here: 3 groups, 2 sexes, across age.

---

# Fake data simulations

```{r}
# create our age variable to range from 20 to 80
set.seed(1234) # this just makes sure we get same answer every time
age <- runif(120, min=20, max=80)
# set up the group and sex variables. Keep it balanced: 20 per group
group <- c(
  rep("G1", 40),
  rep("G2", 40),
  rep("G3", 40))
sex <- c(rep(rep(c("M", "F"), each=20), 3))
# Let's start simple, and assume that sex and group have no impact on
# our outcome, that there is a difference by sex at baseline, and
# that there is no difference by group at baseline
outcome_at_age20 <- 100
sex_diff_at_age_20 <- 3
change_per_year <- 0.5

outcome <- outcome_at_age20 + 
  ifelse(sex == "F", sex_diff_at_age_20, 0) + 
  (age-20)*change_per_year + 
  rnorm(length(age), mean=0, sd=2)

fake <- data.frame(age, sex, group, outcome)

```

---

# Fake data simulations

```{r}
suppressMessages(library(tidyverse))
fake %>% sample_n(18)
```


---

# Fake data simulations

```{r, fig.width=12, fig.height=5}
theme_set(theme_minimal(18))
ggplot(fake) + aes(x=age, y=outcome, colour=group, shape=sex) +
  geom_point(size=3) 
```

---

# Fake data simulations

```{r}
l1 <- lm(outcome ~ sex + group, fake)
summary(l1)
```

---

# Fake data simulations

```{r, fig.height=5, fig.width=12}
fake %>% mutate(l1 = predict(l1)) %>%
  ggplot() + aes(x=age, y=outcome, shape=sex, colour=group) +
  geom_point() + 
  geom_smooth(aes(y=l1), method="lm")
```


---

# Fake data simulations

```{r}
l2 <- lm(outcome ~ age + sex + group, fake)
summary(l2)
```

---

# Fake data simulations

```{r, fig.width=12, fig.height=4}
fake %>% mutate(l2 = predict(l2)) %>%
  ggplot() + aes(x=age, y=outcome, shape=sex, 
                 colour=group, linetype=sex) +
  geom_point() + 
  geom_smooth(aes(y=l2), method="lm")
```

---

# Fake data simulations

```{r}
l3 <- lm(outcome ~ age + sex, fake)
summary(l3)
```

---

# Fake data simulations

```{r, fig.width=12, fig.height=4}
fake %>% mutate(l3 = predict(l3)) %>%
  ggplot() + aes(x=age, y=outcome, shape=sex, 
                 colour=group, linetype=sex) +
  geom_point() + 
  geom_smooth(aes(y=l3), method="lm")
```

---

# Fake data simulations

```{r}
summary(lm(outcome ~ I(age-mean(age)) + sex, fake))
```

---

class: smallercode

# Fake data simulations

```{r}
l4 <- lm(outcome ~ age * sex * group, fake)
summary(l4)
```

---

# Fake data simulations

```{r, fig.width=12, fig.height=4}
fake %>% mutate(l4 = predict(l4)) %>%
  ggplot() + aes(x=age, y=outcome, shape=sex, 
                 colour=group, linetype=sex) +
  geom_point() + 
  geom_smooth(aes(y=l4), method="lm")
```

---

# Interpreting these results

After fitting our models we're left with:

1. coefficient estimates
1. t-statistics
1. p-values

We know if our model assumptions are satisfied our t-statistics
  have a known distribution. 

From this distribution we can figure out the probability of t-statistics
  as large or larger than the one we observed (p-value)

---

# Model comparions

```{r}
anova(l1, l2, l3, l4)
```


---
class: center

# And now for Bayesianism!

---
# Why Bayesian Statistics?

Have you ever...

1. Been confused about what a p-value means?
1. Been frustrated that a difference in significance doesn't mean a significant difference?
1. Known some values for a parameter are impossible but been unable to use that to your advantage?
1. Wanted to ask more interesting questions than whether or not a parameter is or isn't zero?
1. Wanted to use information from the literature to improve your estimates?

---

# Why Bayesian Statistics?

Have you ever...

1. Been confused about what a p-value means?
1. Been frustrated that a difference in significance doesn't mean a significant difference?
1. Known some values for a parameter are impossible but been unable to use that to your advantage?
1. Wanted to ask more interesting questions than whether or not a parameter is or isn't zero?
1. Wanted to use information from the literature to improve your estimates?

Then Bayesian statistics might be right for you!

---

## How you ask?

1. **De-emphasize binary descisions.**
  Bayesians avoid null hypothesis tests, instead focusing on estimating their parameters of 
  interest, and reporting their uncertainty.
  
1. **Posterior Distributions**
  Bayesian analyses produce a distribution of possible parameter values (the posterior), that
  can be used to ask many interesting questions about values. E.g. what is the probability the
  effect in the hippocampus is larger than the effect in the anterior cingulate cortex.
  
1. **Prior Information**
  Bayesian analyses can use prior information. Bayesian analysis requires an *a priori* assessment
  of how likely certain parameters are. This can be vague (uninformative) or can precise (informative)
  and steer your analysis away from nonsensical results.

---

class: center
# Meet The Reverend

Reverend Thomas Bayes


![](images/Thomas_Bayes.gif)

---
class: middle

## Bayes' Theorem

- Bayes noticed this useful property for the probabilities for two events "A" and "B"

$$ \color{red}{P(A | B)} = \frac{{\color{blue}{P(B | A)}\color{orange}{P(A)}}}{\color{magenta}{P(B)}} $$


- $\color{red}{P(A|B)}$: The probability of A given that B happened
- $\color{blue}{P(B|A)}$: The probability of B given that A happened
- $\color{orange}{P(A)}$: The probability of A
- $\color{magenta}{P(B)}$: the probability of B

- Bayes did this in the context of the binomial distribution

---
class: middle
# But who's that behind him!

---
class: center

# It's Pierre-Simon Laplace

![](images/Pierre-Simon-Laplace.jpg)

---

## Bayesian Statistics

- Laplace generalized Bayes Theorem into it's modern form. While working on sex-ratios in French births.
- For light reading on the history of bayesianism consider reading [the theory that would not die](https://yalebooks.yale.edu/book/9780300188226/theory-would-not-die)

## Bayes in brief
- Start with some parameters $\theta$
- Collect some data $D$
- And deduce the probability of different values of $\theta$ given that you observed $D$
- Key difference between Bayesianism and Frequentism is that view that $\theta$ has an associated
  probability distribution. In frequentism $\theta$ is an unknown constant.

---

# Different Probabilities

- Frequentists believe that probabilities represent the long-run proportion of events
- Under this model $P(\theta)$ doesn't make much sense. 
- Ramsey and DeFinetti showed that probability can also represent degree of belief.
- Under this model $P(\theta)$ is an assesment of what you think the the parameter will be.
- For some of the philosophy underpinning bayesian reasoning consider reading 
  [Bayesian philosophy of science](http://www.laeuferpaar.de/Papers/BookFrame_v1.pdf)
  
---
class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} = \frac{{\color{blue}{P(D | \theta)}\color{orange}{P(\theta)}}}{\color{magenta}{\int P(D | \theta)P(\theta)d\theta}} $$
**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

**Normalizing Constant**: $\color{magenta}{\int P(D | \theta)P(\theta)d\theta}$

The probability of the data averaged over all possible parameter sets


---

class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} \propto \color{blue}{P(D | \theta)}\color{orange}{P(\theta)}$$

**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

---

class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} \propto \color{orange}{P(\theta)}\color{blue}{P(D | \theta)}$$

**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Pardon the re-ordering**

---
class: middle

# Posterior

$\color{red}{P(\theta|D)}$

- The goal of bayesian statistics
- The posterior is probability distribution over parameters.
- Depends on the data we observed.
- Can be used to answer interesting questions. For
example how likely is an effect between two biologically meaninful boundaries.

---
class: middle

# Prior

$\color{orange}{P(\theta)}$

- This is what we knew before the experiment. 
- The prior is also a probability distribution over parameters.
- Doesn't depend on the data we saw.
- Gives a probability for any value the parameters could take.

---
class: middle

# Likelihood

$\color{blue}{P(D | \theta)}$

- This is how probable our data is given a hypothetical parameter set
- The likelihood is a probability distribution over data (not parameters)
- Is still a function of parameters.

---

# In words

$$ \color{red}{P(\theta | D)} \propto \color{orange}{P(\theta)}\color{blue}{P(D | \theta)}$$

The <font color="red">probability of parameters given our data</font> is proportional to <font color="orange">how probable we
thought they were before</font> adjusted by <font color="blue">how well they agree with the data we saw</font>.

![](images/posterior.gif)

---

# A first example

- Let's revisit linear modelling but this time from a bayesian stand-point.

$$ \textbf{y} = X\mathbf{\beta} + \mathbf{\epsilon} $$ 

We'll make our probabilistic views explicit

$$ \mathbf{\epsilon} \sim \mathbb{N}(0, \sigma) $$

$\epsilon$ is normally distributed with some unknown variance $\sigma$

---


# Frequentist interpretation

- In frequentism $\mathbf{\beta}$ is some fixed value.
- We can estimate standard errors for $\beta$ and get p-values
  (likelihoods) that each component of $\mathbf{\beta}$ is zero.
  
# Bayesian interpretation

- In bayesianism $\mathbf{\beta}$ is a random variable that we're trying
  to learn about.
- In order to do this we have specify our prior belief about $\mathbf{\beta}$
- If we say we know nothing about $\mathbf{\beta}$, we get identical estimates
  to frequentism
- For our model we'll say $\beta \sim \mathbb{N}(0,22.5)$, the default.

---

# Fit a bayesian linear model

- For this we'll use the package `rstanarm`
- 

```{r}
suppressMessages(library(rstanarm))
bl <- stan_glm(outcome ~ age + sex + group, data = fake)
```

---

# How'd we do

```{r}
bl
```

---

# How does `lm` do?

```{r}
lmod <- lm(outcome ~ age + sex + group, fake)
summary(lmod)
```

---

# Side-By-Side

```{r}
coef(bl)
coef(lmod)
```

---

# Let's look at the posterior

```{r, fig.height = 4, fig.width=12}
suppressPackageStartupMessages(library(bayesplot))
mcmc_areas(as.matrix(bl), pars=c("age"))
```
---

# Let's look at the posterior

```{r, fig.height = 4, fig.width=12}
mcmc_areas(as.matrix(bl), regex_pars = "sex|group")
```

---

# What's happening here?

- `rstanarm` is creating a posterior for us, but how?
- in most bayesian textbooks this is shown first analytically for simple models.
  *this is not what stan does*
- Stan *approximates* the posterior using samples
- Samples are generated with markov-chain monte carlo (MCMC)
- For more details on the technique see Michael Betancourt's [A conceptual introduction to Hamiltonian Monte Carlo](https://arxiv.org/abs/1701.02434)

---

# The posterior revisited

```{r}
bl_post <- as.matrix(bl)

str(bl_post[,"age"])
summary(bl_post[,"age"])
```

---

# What do we gain?

Intuitive use of probabilities:

What is the chance that the sex effect is greater than 0? Than 0.5?

```{r}
bl_post %>% as.data.frame %>%
  select(age) %>%
  summarize(gt0=mean(age>0),
            gt05=mean(age>0.5))
```


---

# Priors

```{r}
prior_summary(bl)
```

---

# Priors

```{r}
priors <- normal(0, c(2.5, 2.5, 0.5, 0.5), autoscale = F)
bl2 <- update(bl, prior=priors)
```

---

# Priors and posteriors

.pull-left[
```{r}
mcmc_areas(as.matrix(bl),  
 regex_pars = "sex|group")
```
]
.pull-right[
```{r}
mcmc_areas(as.matrix(bl2), 
 regex_pars = "sex|group")
```
]


---

# Priors and posteriors

```{r p1, fig.height=3, fig.width=12, include=F, fig.show='hold'}
bl_post_df <- bl_post %>% as.data.frame %>% mutate(type="posterior")
bl_priors_df <- as.matrix(update(bl, prior_PD=T, refresh=-1)) %>% as.data.frame %>% mutate(type="prior")
rbind(bl_post_df, bl_priors_df) %>% ggplot() + aes(groupG2, fill=type) + geom_density() +ggtitle("defaults")

```

![](`r knitr::fig_chunk("p1", "png")`)



```{r p2, fig.height=3, fig.width=12, include=F, fig.show='hold'}
bl2_post_df <- as.matrix(bl2) %>% as.data.frame %>% mutate(type="posterior")
bl2_priors_df <- as.matrix(update(bl2, prior_PD=T, refresh=-1)) %>% as.data.frame %>% mutate(type="prior")
rbind(bl2_post_df, bl2_priors_df) %>% ggplot() + aes(groupG2, fill=type) + geom_density()+ggtitle("constrained")

```

![](`r knitr::fig_chunk("p2", "png")`)

---

# With real data now

Reload the data

```{r}
mice <- read_csv("mice.csv") %>%
  inner_join(read_csv("volumes.csv")) %>%
  mutate(Genotype = factor(Genotype, 
            levels=c("CREB +/+", "CREB +/-", "CREB -/-")),
         Condition=factor(Condition, levels=
      c("Standard", "Isolated Standard", "Exercise", "Enriched")))
```


---

# Model at baseline

```{r}
b_base <- mice %>%
  filter(Timepoint == "Pre1") %>%
  stan_glm(hippocampus ~ Sex + Condition + Genotype, data=.)
```

---
class: smallercode

# Model at baseline

```{r}
summary(b_base, digits=2)
```

---

# Model at baseline

```{r, fig.height=6, fig.width=12}
mcmc_intervals(as.matrix(b_base), regex_pars = "Condition|Genotype|Sex")
```

---

# Model at baseline

Is CREB +/- different from CREB -/-?

```{r}
b_base_post <- as.matrix(b_base)
colnames(b_base_post)
mean(b_base_post[,"GenotypeCREB +/-"] > b_base_post[,"GenotypeCREB -/-"])
```


---



# Assignment (due Friday)

.medium[
Keep updating the same Rmarkdown file for the entire course.

1. Compare accuracy of K-NN with logistic regression in predicting amygdala size on test dataset.

1. Split mice data into training, test, and validation. Optimize *K* hyperparameter
  of *K*-NN so the model has a higher performance in predicting amygdala size on test dataset. Report at least two different measures of binary classification on validation data. Use knn function in R.

1. Use random forest to predict genotype given volume of all regions in the brain. Optimize the number of trees in the random forest. Compare your training and validation accuracy, specificity, and sensitivity for each genotype (with a plot). Which variables have the highest feature importance (show in a plot)?

1. Generate a fake dataset with an interaction, and compute and compare linear model and bayesian linear model outputs.

1. Using whatever mix of bayesian, frequentist, or machine learning algorithms you like, conclude with a final statement about the effect of Genotype, Condition, and Time on hippocampal volume.

]
